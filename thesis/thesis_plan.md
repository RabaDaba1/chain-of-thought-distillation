# Engineering Thesis Plan: Enhancing Small Language Models via Chain-of-Thought Distillation

## 1. Thesis Overview

*   **Title:** Enhancing Small Language Models via Chain-of-Thought Distillation
*   **Author:** Kacper Rabczewski
*   **Supervisor:** Dr. Krzysztof Kluza
*   **Objective:** To investigate and verify the effectiveness of Chain-of-Thought (CoT) distillation from a large language model (LLM) to a small language model (SLM) for improving mathematical reasoning capabilities. This involves replicating the SCoTD (Self-consistent Chain-of-Thought Distillation) methodology.
*   **Target Page Count:** 40-50 pages.

---

## 2. Detailed Table of Contents (only a draft)

