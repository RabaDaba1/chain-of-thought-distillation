{
  "best_global_step": 1200,
  "best_metric": 0.21416567265987396,
  "best_model_checkpoint": "/workspace/chain-of-thought-distillation/code/artifacts/models/qwen2.5_3b_sctod_lora/checkpoint-1200",
  "epoch": 1.1182108626198084,
  "eval_steps": 200,
  "global_step": 1400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007987220447284345,
      "grad_norm": 0.44920799136161804,
      "learning_rate": 2.368421052631579e-06,
      "loss": 0.4259,
      "step": 10
    },
    {
      "epoch": 0.01597444089456869,
      "grad_norm": 0.5478562712669373,
      "learning_rate": 5e-06,
      "loss": 0.4241,
      "step": 20
    },
    {
      "epoch": 0.023961661341853034,
      "grad_norm": 0.64439857006073,
      "learning_rate": 7.631578947368423e-06,
      "loss": 0.402,
      "step": 30
    },
    {
      "epoch": 0.03194888178913738,
      "grad_norm": 0.781541109085083,
      "learning_rate": 1.0263157894736844e-05,
      "loss": 0.3688,
      "step": 40
    },
    {
      "epoch": 0.039936102236421724,
      "grad_norm": 0.7172583341598511,
      "learning_rate": 1.2894736842105264e-05,
      "loss": 0.2802,
      "step": 50
    },
    {
      "epoch": 0.04792332268370607,
      "grad_norm": 0.3349953293800354,
      "learning_rate": 1.5526315789473686e-05,
      "loss": 0.2764,
      "step": 60
    },
    {
      "epoch": 0.05591054313099041,
      "grad_norm": 0.32718151807785034,
      "learning_rate": 1.8157894736842107e-05,
      "loss": 0.2641,
      "step": 70
    },
    {
      "epoch": 0.06389776357827476,
      "grad_norm": 0.33166050910949707,
      "learning_rate": 1.997528830313015e-05,
      "loss": 0.2522,
      "step": 80
    },
    {
      "epoch": 0.07188498402555911,
      "grad_norm": 0.5788504481315613,
      "learning_rate": 1.9892915980230645e-05,
      "loss": 0.254,
      "step": 90
    },
    {
      "epoch": 0.07987220447284345,
      "grad_norm": 0.738533079624176,
      "learning_rate": 1.9810543657331137e-05,
      "loss": 0.241,
      "step": 100
    },
    {
      "epoch": 0.0878594249201278,
      "grad_norm": 0.27497589588165283,
      "learning_rate": 1.9728171334431633e-05,
      "loss": 0.2586,
      "step": 110
    },
    {
      "epoch": 0.09584664536741214,
      "grad_norm": 0.3555050790309906,
      "learning_rate": 1.9645799011532128e-05,
      "loss": 0.266,
      "step": 120
    },
    {
      "epoch": 0.10383386581469649,
      "grad_norm": 0.3833768665790558,
      "learning_rate": 1.956342668863262e-05,
      "loss": 0.2421,
      "step": 130
    },
    {
      "epoch": 0.11182108626198083,
      "grad_norm": 0.45467761158943176,
      "learning_rate": 1.9481054365733116e-05,
      "loss": 0.2332,
      "step": 140
    },
    {
      "epoch": 0.11980830670926518,
      "grad_norm": 1.0900142192840576,
      "learning_rate": 1.939868204283361e-05,
      "loss": 0.2052,
      "step": 150
    },
    {
      "epoch": 0.12779552715654952,
      "grad_norm": 0.3489314317703247,
      "learning_rate": 1.9316309719934103e-05,
      "loss": 0.2721,
      "step": 160
    },
    {
      "epoch": 0.13578274760383385,
      "grad_norm": 0.3407534658908844,
      "learning_rate": 1.92339373970346e-05,
      "loss": 0.2454,
      "step": 170
    },
    {
      "epoch": 0.14376996805111822,
      "grad_norm": 0.3607296645641327,
      "learning_rate": 1.915156507413509e-05,
      "loss": 0.2442,
      "step": 180
    },
    {
      "epoch": 0.15175718849840256,
      "grad_norm": 0.39809244871139526,
      "learning_rate": 1.9069192751235586e-05,
      "loss": 0.2294,
      "step": 190
    },
    {
      "epoch": 0.1597444089456869,
      "grad_norm": 0.783992350101471,
      "learning_rate": 1.898682042833608e-05,
      "loss": 0.2385,
      "step": 200
    },
    {
      "epoch": 0.1597444089456869,
      "eval_loss": 0.2347453236579895,
      "eval_runtime": 313.2597,
      "eval_samples_per_second": 15.719,
      "eval_steps_per_second": 1.966,
      "step": 200
    },
    {
      "epoch": 0.16773162939297126,
      "grad_norm": 0.3828473389148712,
      "learning_rate": 1.8904448105436574e-05,
      "loss": 0.2816,
      "step": 210
    },
    {
      "epoch": 0.1757188498402556,
      "grad_norm": 0.3555664122104645,
      "learning_rate": 1.882207578253707e-05,
      "loss": 0.2194,
      "step": 220
    },
    {
      "epoch": 0.18370607028753994,
      "grad_norm": 0.4430045783519745,
      "learning_rate": 1.8739703459637565e-05,
      "loss": 0.2293,
      "step": 230
    },
    {
      "epoch": 0.19169329073482427,
      "grad_norm": 0.4656457006931305,
      "learning_rate": 1.8657331136738057e-05,
      "loss": 0.2241,
      "step": 240
    },
    {
      "epoch": 0.19968051118210864,
      "grad_norm": 0.9675964713096619,
      "learning_rate": 1.8574958813838552e-05,
      "loss": 0.2006,
      "step": 250
    },
    {
      "epoch": 0.20766773162939298,
      "grad_norm": 0.4152325987815857,
      "learning_rate": 1.8492586490939048e-05,
      "loss": 0.2838,
      "step": 260
    },
    {
      "epoch": 0.21565495207667731,
      "grad_norm": 0.4031304121017456,
      "learning_rate": 1.841021416803954e-05,
      "loss": 0.2459,
      "step": 270
    },
    {
      "epoch": 0.22364217252396165,
      "grad_norm": 0.3939160704612732,
      "learning_rate": 1.8327841845140035e-05,
      "loss": 0.2091,
      "step": 280
    },
    {
      "epoch": 0.23162939297124602,
      "grad_norm": 0.44553112983703613,
      "learning_rate": 1.8245469522240527e-05,
      "loss": 0.2107,
      "step": 290
    },
    {
      "epoch": 0.23961661341853036,
      "grad_norm": 0.6045382618904114,
      "learning_rate": 1.8163097199341023e-05,
      "loss": 0.2142,
      "step": 300
    },
    {
      "epoch": 0.2476038338658147,
      "grad_norm": 0.41420838236808777,
      "learning_rate": 1.8080724876441518e-05,
      "loss": 0.2774,
      "step": 310
    },
    {
      "epoch": 0.25559105431309903,
      "grad_norm": 0.3727962076663971,
      "learning_rate": 1.799835255354201e-05,
      "loss": 0.2206,
      "step": 320
    },
    {
      "epoch": 0.26357827476038337,
      "grad_norm": 0.43286237120628357,
      "learning_rate": 1.7915980230642506e-05,
      "loss": 0.2003,
      "step": 330
    },
    {
      "epoch": 0.2715654952076677,
      "grad_norm": 0.6512818932533264,
      "learning_rate": 1.7833607907743e-05,
      "loss": 0.2268,
      "step": 340
    },
    {
      "epoch": 0.2795527156549521,
      "grad_norm": 0.7189554572105408,
      "learning_rate": 1.7751235584843493e-05,
      "loss": 0.231,
      "step": 350
    },
    {
      "epoch": 0.28753993610223644,
      "grad_norm": 0.37447264790534973,
      "learning_rate": 1.766886326194399e-05,
      "loss": 0.2604,
      "step": 360
    },
    {
      "epoch": 0.2955271565495208,
      "grad_norm": 0.4072926342487335,
      "learning_rate": 1.7586490939044484e-05,
      "loss": 0.205,
      "step": 370
    },
    {
      "epoch": 0.3035143769968051,
      "grad_norm": 0.6282653212547302,
      "learning_rate": 1.7504118616144976e-05,
      "loss": 0.2179,
      "step": 380
    },
    {
      "epoch": 0.31150159744408945,
      "grad_norm": 0.6530368328094482,
      "learning_rate": 1.742174629324547e-05,
      "loss": 0.2019,
      "step": 390
    },
    {
      "epoch": 0.3194888178913738,
      "grad_norm": 0.7804664969444275,
      "learning_rate": 1.7339373970345964e-05,
      "loss": 0.1904,
      "step": 400
    },
    {
      "epoch": 0.3194888178913738,
      "eval_loss": 0.22524821758270264,
      "eval_runtime": 313.2662,
      "eval_samples_per_second": 15.718,
      "eval_steps_per_second": 1.966,
      "step": 400
    },
    {
      "epoch": 0.3274760383386581,
      "grad_norm": 0.4409531354904175,
      "learning_rate": 1.725700164744646e-05,
      "loss": 0.2492,
      "step": 410
    },
    {
      "epoch": 0.3354632587859425,
      "grad_norm": 0.5059384107589722,
      "learning_rate": 1.7174629324546955e-05,
      "loss": 0.2236,
      "step": 420
    },
    {
      "epoch": 0.34345047923322686,
      "grad_norm": 0.4439002573490143,
      "learning_rate": 1.7092257001647447e-05,
      "loss": 0.214,
      "step": 430
    },
    {
      "epoch": 0.3514376996805112,
      "grad_norm": 0.5369375944137573,
      "learning_rate": 1.7009884678747942e-05,
      "loss": 0.2119,
      "step": 440
    },
    {
      "epoch": 0.35942492012779553,
      "grad_norm": 0.7100391983985901,
      "learning_rate": 1.6927512355848437e-05,
      "loss": 0.1898,
      "step": 450
    },
    {
      "epoch": 0.36741214057507987,
      "grad_norm": 0.4246174097061157,
      "learning_rate": 1.684514003294893e-05,
      "loss": 0.2712,
      "step": 460
    },
    {
      "epoch": 0.3753993610223642,
      "grad_norm": 0.41814306378364563,
      "learning_rate": 1.6762767710049425e-05,
      "loss": 0.2096,
      "step": 470
    },
    {
      "epoch": 0.38338658146964855,
      "grad_norm": 0.4847307801246643,
      "learning_rate": 1.668039538714992e-05,
      "loss": 0.1944,
      "step": 480
    },
    {
      "epoch": 0.3913738019169329,
      "grad_norm": 0.5560535192489624,
      "learning_rate": 1.6598023064250413e-05,
      "loss": 0.204,
      "step": 490
    },
    {
      "epoch": 0.3993610223642173,
      "grad_norm": 0.7622370719909668,
      "learning_rate": 1.6515650741350908e-05,
      "loss": 0.1861,
      "step": 500
    },
    {
      "epoch": 0.4073482428115016,
      "grad_norm": 0.4406016767024994,
      "learning_rate": 1.64332784184514e-05,
      "loss": 0.2341,
      "step": 510
    },
    {
      "epoch": 0.41533546325878595,
      "grad_norm": 0.5279045701026917,
      "learning_rate": 1.6350906095551896e-05,
      "loss": 0.2157,
      "step": 520
    },
    {
      "epoch": 0.4233226837060703,
      "grad_norm": 0.4395720660686493,
      "learning_rate": 1.626853377265239e-05,
      "loss": 0.2054,
      "step": 530
    },
    {
      "epoch": 0.43130990415335463,
      "grad_norm": 0.4893757402896881,
      "learning_rate": 1.6186161449752883e-05,
      "loss": 0.19,
      "step": 540
    },
    {
      "epoch": 0.43929712460063897,
      "grad_norm": 0.9823312163352966,
      "learning_rate": 1.610378912685338e-05,
      "loss": 0.1932,
      "step": 550
    },
    {
      "epoch": 0.4472843450479233,
      "grad_norm": 0.3900362253189087,
      "learning_rate": 1.6021416803953874e-05,
      "loss": 0.2293,
      "step": 560
    },
    {
      "epoch": 0.45527156549520764,
      "grad_norm": 0.42399728298187256,
      "learning_rate": 1.5939044481054366e-05,
      "loss": 0.2136,
      "step": 570
    },
    {
      "epoch": 0.46325878594249204,
      "grad_norm": 0.4570903480052948,
      "learning_rate": 1.585667215815486e-05,
      "loss": 0.2056,
      "step": 580
    },
    {
      "epoch": 0.4712460063897764,
      "grad_norm": 0.5878376960754395,
      "learning_rate": 1.5774299835255357e-05,
      "loss": 0.1923,
      "step": 590
    },
    {
      "epoch": 0.4792332268370607,
      "grad_norm": 0.858721911907196,
      "learning_rate": 1.569192751235585e-05,
      "loss": 0.1711,
      "step": 600
    },
    {
      "epoch": 0.4792332268370607,
      "eval_loss": 0.21960121393203735,
      "eval_runtime": 313.5447,
      "eval_samples_per_second": 15.704,
      "eval_steps_per_second": 1.965,
      "step": 600
    },
    {
      "epoch": 0.48722044728434505,
      "grad_norm": 0.4722106456756592,
      "learning_rate": 1.5609555189456344e-05,
      "loss": 0.2177,
      "step": 610
    },
    {
      "epoch": 0.4952076677316294,
      "grad_norm": 0.49091285467147827,
      "learning_rate": 1.5527182866556837e-05,
      "loss": 0.2041,
      "step": 620
    },
    {
      "epoch": 0.5031948881789138,
      "grad_norm": 0.482882559299469,
      "learning_rate": 1.5444810543657332e-05,
      "loss": 0.193,
      "step": 630
    },
    {
      "epoch": 0.5111821086261981,
      "grad_norm": 0.46936753392219543,
      "learning_rate": 1.5362438220757827e-05,
      "loss": 0.1885,
      "step": 640
    },
    {
      "epoch": 0.5191693290734825,
      "grad_norm": 0.8889336585998535,
      "learning_rate": 1.528006589785832e-05,
      "loss": 0.2006,
      "step": 650
    },
    {
      "epoch": 0.5271565495207667,
      "grad_norm": 0.4776572287082672,
      "learning_rate": 1.5197693574958817e-05,
      "loss": 0.2336,
      "step": 660
    },
    {
      "epoch": 0.5351437699680511,
      "grad_norm": 0.4011211693286896,
      "learning_rate": 1.5115321252059309e-05,
      "loss": 0.2047,
      "step": 670
    },
    {
      "epoch": 0.5431309904153354,
      "grad_norm": 0.4287492334842682,
      "learning_rate": 1.5032948929159803e-05,
      "loss": 0.1964,
      "step": 680
    },
    {
      "epoch": 0.5511182108626198,
      "grad_norm": 0.5533216595649719,
      "learning_rate": 1.4950576606260298e-05,
      "loss": 0.1879,
      "step": 690
    },
    {
      "epoch": 0.5591054313099042,
      "grad_norm": 0.9293469786643982,
      "learning_rate": 1.4868204283360792e-05,
      "loss": 0.1981,
      "step": 700
    },
    {
      "epoch": 0.5670926517571885,
      "grad_norm": 0.4562142491340637,
      "learning_rate": 1.4785831960461286e-05,
      "loss": 0.2407,
      "step": 710
    },
    {
      "epoch": 0.5750798722044729,
      "grad_norm": 0.520653486251831,
      "learning_rate": 1.4703459637561781e-05,
      "loss": 0.1876,
      "step": 720
    },
    {
      "epoch": 0.5830670926517572,
      "grad_norm": 0.46949687600135803,
      "learning_rate": 1.4621087314662275e-05,
      "loss": 0.1987,
      "step": 730
    },
    {
      "epoch": 0.5910543130990416,
      "grad_norm": 0.5315477848052979,
      "learning_rate": 1.4538714991762769e-05,
      "loss": 0.1902,
      "step": 740
    },
    {
      "epoch": 0.5990415335463258,
      "grad_norm": 0.8182469010353088,
      "learning_rate": 1.4456342668863264e-05,
      "loss": 0.1742,
      "step": 750
    },
    {
      "epoch": 0.6070287539936102,
      "grad_norm": 0.43958500027656555,
      "learning_rate": 1.4373970345963758e-05,
      "loss": 0.2506,
      "step": 760
    },
    {
      "epoch": 0.6150159744408946,
      "grad_norm": 0.5536130666732788,
      "learning_rate": 1.4291598023064253e-05,
      "loss": 0.1995,
      "step": 770
    },
    {
      "epoch": 0.6230031948881789,
      "grad_norm": 0.5850652456283569,
      "learning_rate": 1.4209225700164745e-05,
      "loss": 0.2086,
      "step": 780
    },
    {
      "epoch": 0.6309904153354633,
      "grad_norm": 0.5850826501846313,
      "learning_rate": 1.4126853377265239e-05,
      "loss": 0.1884,
      "step": 790
    },
    {
      "epoch": 0.6389776357827476,
      "grad_norm": 0.7617289423942566,
      "learning_rate": 1.4044481054365734e-05,
      "loss": 0.1741,
      "step": 800
    },
    {
      "epoch": 0.6389776357827476,
      "eval_loss": 0.21880333125591278,
      "eval_runtime": 313.4301,
      "eval_samples_per_second": 15.71,
      "eval_steps_per_second": 1.965,
      "step": 800
    },
    {
      "epoch": 0.646964856230032,
      "grad_norm": 0.5001210570335388,
      "learning_rate": 1.3962108731466228e-05,
      "loss": 0.2348,
      "step": 810
    },
    {
      "epoch": 0.6549520766773163,
      "grad_norm": 0.48695093393325806,
      "learning_rate": 1.3879736408566722e-05,
      "loss": 0.192,
      "step": 820
    },
    {
      "epoch": 0.6629392971246006,
      "grad_norm": 0.5900803208351135,
      "learning_rate": 1.3797364085667217e-05,
      "loss": 0.2011,
      "step": 830
    },
    {
      "epoch": 0.670926517571885,
      "grad_norm": 0.582449197769165,
      "learning_rate": 1.3714991762767711e-05,
      "loss": 0.1802,
      "step": 840
    },
    {
      "epoch": 0.6789137380191693,
      "grad_norm": 0.8144724369049072,
      "learning_rate": 1.3632619439868205e-05,
      "loss": 0.1697,
      "step": 850
    },
    {
      "epoch": 0.6869009584664537,
      "grad_norm": 0.43262362480163574,
      "learning_rate": 1.35502471169687e-05,
      "loss": 0.2218,
      "step": 860
    },
    {
      "epoch": 0.694888178913738,
      "grad_norm": 0.5596583485603333,
      "learning_rate": 1.3467874794069194e-05,
      "loss": 0.1992,
      "step": 870
    },
    {
      "epoch": 0.7028753993610224,
      "grad_norm": 0.5808945298194885,
      "learning_rate": 1.338550247116969e-05,
      "loss": 0.192,
      "step": 880
    },
    {
      "epoch": 0.7108626198083067,
      "grad_norm": 0.5475974082946777,
      "learning_rate": 1.3303130148270182e-05,
      "loss": 0.2033,
      "step": 890
    },
    {
      "epoch": 0.7188498402555911,
      "grad_norm": 0.813278317451477,
      "learning_rate": 1.3220757825370676e-05,
      "loss": 0.2003,
      "step": 900
    },
    {
      "epoch": 0.7268370607028753,
      "grad_norm": 0.3950868844985962,
      "learning_rate": 1.3138385502471171e-05,
      "loss": 0.2463,
      "step": 910
    },
    {
      "epoch": 0.7348242811501597,
      "grad_norm": 0.4109989106655121,
      "learning_rate": 1.3056013179571665e-05,
      "loss": 0.1858,
      "step": 920
    },
    {
      "epoch": 0.7428115015974441,
      "grad_norm": 0.45381686091423035,
      "learning_rate": 1.2973640856672158e-05,
      "loss": 0.1865,
      "step": 930
    },
    {
      "epoch": 0.7507987220447284,
      "grad_norm": 0.5880612134933472,
      "learning_rate": 1.2891268533772654e-05,
      "loss": 0.1881,
      "step": 940
    },
    {
      "epoch": 0.7587859424920128,
      "grad_norm": 0.9123706817626953,
      "learning_rate": 1.2808896210873148e-05,
      "loss": 0.1739,
      "step": 950
    },
    {
      "epoch": 0.7667731629392971,
      "grad_norm": 0.433439701795578,
      "learning_rate": 1.2726523887973641e-05,
      "loss": 0.2439,
      "step": 960
    },
    {
      "epoch": 0.7747603833865815,
      "grad_norm": 0.5726803541183472,
      "learning_rate": 1.2644151565074137e-05,
      "loss": 0.2088,
      "step": 970
    },
    {
      "epoch": 0.7827476038338658,
      "grad_norm": 0.5217985510826111,
      "learning_rate": 1.2561779242174629e-05,
      "loss": 0.1771,
      "step": 980
    },
    {
      "epoch": 0.7907348242811502,
      "grad_norm": 0.7200590968132019,
      "learning_rate": 1.2479406919275126e-05,
      "loss": 0.1906,
      "step": 990
    },
    {
      "epoch": 0.7987220447284346,
      "grad_norm": 0.8170542120933533,
      "learning_rate": 1.2397034596375618e-05,
      "loss": 0.1811,
      "step": 1000
    },
    {
      "epoch": 0.7987220447284346,
      "eval_loss": 0.21569271385669708,
      "eval_runtime": 312.7093,
      "eval_samples_per_second": 15.746,
      "eval_steps_per_second": 1.97,
      "step": 1000
    },
    {
      "epoch": 0.8067092651757188,
      "grad_norm": 0.5033935904502869,
      "learning_rate": 1.2314662273476112e-05,
      "loss": 0.2507,
      "step": 1010
    },
    {
      "epoch": 0.8146964856230032,
      "grad_norm": 0.5583078265190125,
      "learning_rate": 1.2232289950576607e-05,
      "loss": 0.1707,
      "step": 1020
    },
    {
      "epoch": 0.8226837060702875,
      "grad_norm": 0.6333993077278137,
      "learning_rate": 1.2149917627677101e-05,
      "loss": 0.2182,
      "step": 1030
    },
    {
      "epoch": 0.8306709265175719,
      "grad_norm": 0.5896086692810059,
      "learning_rate": 1.2067545304777595e-05,
      "loss": 0.1894,
      "step": 1040
    },
    {
      "epoch": 0.8386581469648562,
      "grad_norm": 0.9265179634094238,
      "learning_rate": 1.198517298187809e-05,
      "loss": 0.1753,
      "step": 1050
    },
    {
      "epoch": 0.8466453674121406,
      "grad_norm": 0.5024304986000061,
      "learning_rate": 1.1902800658978584e-05,
      "loss": 0.237,
      "step": 1060
    },
    {
      "epoch": 0.854632587859425,
      "grad_norm": 0.5491744875907898,
      "learning_rate": 1.182042833607908e-05,
      "loss": 0.1927,
      "step": 1070
    },
    {
      "epoch": 0.8626198083067093,
      "grad_norm": 0.5373201370239258,
      "learning_rate": 1.1738056013179573e-05,
      "loss": 0.1878,
      "step": 1080
    },
    {
      "epoch": 0.8706070287539937,
      "grad_norm": 0.7762912511825562,
      "learning_rate": 1.1655683690280065e-05,
      "loss": 0.1938,
      "step": 1090
    },
    {
      "epoch": 0.8785942492012779,
      "grad_norm": 0.9375547766685486,
      "learning_rate": 1.1573311367380563e-05,
      "loss": 0.1868,
      "step": 1100
    },
    {
      "epoch": 0.8865814696485623,
      "grad_norm": 0.46038559079170227,
      "learning_rate": 1.1490939044481055e-05,
      "loss": 0.207,
      "step": 1110
    },
    {
      "epoch": 0.8945686900958466,
      "grad_norm": 0.5392518043518066,
      "learning_rate": 1.1408566721581548e-05,
      "loss": 0.1936,
      "step": 1120
    },
    {
      "epoch": 0.902555910543131,
      "grad_norm": 0.5371338129043579,
      "learning_rate": 1.1326194398682044e-05,
      "loss": 0.1784,
      "step": 1130
    },
    {
      "epoch": 0.9105431309904153,
      "grad_norm": 0.6404017806053162,
      "learning_rate": 1.1243822075782538e-05,
      "loss": 0.1814,
      "step": 1140
    },
    {
      "epoch": 0.9185303514376997,
      "grad_norm": 0.8535977602005005,
      "learning_rate": 1.1161449752883031e-05,
      "loss": 0.1686,
      "step": 1150
    },
    {
      "epoch": 0.9265175718849841,
      "grad_norm": 0.4798434376716614,
      "learning_rate": 1.1079077429983527e-05,
      "loss": 0.2408,
      "step": 1160
    },
    {
      "epoch": 0.9345047923322684,
      "grad_norm": 0.5542537569999695,
      "learning_rate": 1.099670510708402e-05,
      "loss": 0.1969,
      "step": 1170
    },
    {
      "epoch": 0.9424920127795527,
      "grad_norm": 0.5037055611610413,
      "learning_rate": 1.0914332784184516e-05,
      "loss": 0.186,
      "step": 1180
    },
    {
      "epoch": 0.950479233226837,
      "grad_norm": 0.6753556728363037,
      "learning_rate": 1.083196046128501e-05,
      "loss": 0.1771,
      "step": 1190
    },
    {
      "epoch": 0.9584664536741214,
      "grad_norm": 0.8246203660964966,
      "learning_rate": 1.0749588138385502e-05,
      "loss": 0.1902,
      "step": 1200
    },
    {
      "epoch": 0.9584664536741214,
      "eval_loss": 0.21416567265987396,
      "eval_runtime": 313.6146,
      "eval_samples_per_second": 15.701,
      "eval_steps_per_second": 1.964,
      "step": 1200
    },
    {
      "epoch": 0.9664536741214057,
      "grad_norm": 0.5913611054420471,
      "learning_rate": 1.0667215815485999e-05,
      "loss": 0.2245,
      "step": 1210
    },
    {
      "epoch": 0.9744408945686901,
      "grad_norm": 0.5288540720939636,
      "learning_rate": 1.0584843492586491e-05,
      "loss": 0.2051,
      "step": 1220
    },
    {
      "epoch": 0.9824281150159745,
      "grad_norm": 0.5919678211212158,
      "learning_rate": 1.0502471169686985e-05,
      "loss": 0.183,
      "step": 1230
    },
    {
      "epoch": 0.9904153354632588,
      "grad_norm": 0.6711451411247253,
      "learning_rate": 1.042009884678748e-05,
      "loss": 0.1797,
      "step": 1240
    },
    {
      "epoch": 0.9984025559105432,
      "grad_norm": 0.7753933668136597,
      "learning_rate": 1.0337726523887974e-05,
      "loss": 0.1719,
      "step": 1250
    },
    {
      "epoch": 1.0063897763578276,
      "grad_norm": 0.47269681096076965,
      "learning_rate": 1.0255354200988468e-05,
      "loss": 0.217,
      "step": 1260
    },
    {
      "epoch": 1.0143769968051117,
      "grad_norm": 0.4897841513156891,
      "learning_rate": 1.0172981878088963e-05,
      "loss": 0.1881,
      "step": 1270
    },
    {
      "epoch": 1.0223642172523961,
      "grad_norm": 0.6139670014381409,
      "learning_rate": 1.0090609555189457e-05,
      "loss": 0.1765,
      "step": 1280
    },
    {
      "epoch": 1.0303514376996805,
      "grad_norm": 0.6536454558372498,
      "learning_rate": 1.0008237232289953e-05,
      "loss": 0.173,
      "step": 1290
    },
    {
      "epoch": 1.038338658146965,
      "grad_norm": 0.728142499923706,
      "learning_rate": 9.925864909390446e-06,
      "loss": 0.1634,
      "step": 1300
    },
    {
      "epoch": 1.0463258785942493,
      "grad_norm": 0.5829293727874756,
      "learning_rate": 9.84349258649094e-06,
      "loss": 0.2132,
      "step": 1310
    },
    {
      "epoch": 1.0543130990415335,
      "grad_norm": 0.49110147356987,
      "learning_rate": 9.761120263591434e-06,
      "loss": 0.1689,
      "step": 1320
    },
    {
      "epoch": 1.0623003194888179,
      "grad_norm": 0.6664767265319824,
      "learning_rate": 9.678747940691928e-06,
      "loss": 0.1798,
      "step": 1330
    },
    {
      "epoch": 1.0702875399361023,
      "grad_norm": 0.5464897751808167,
      "learning_rate": 9.596375617792423e-06,
      "loss": 0.1658,
      "step": 1340
    },
    {
      "epoch": 1.0782747603833867,
      "grad_norm": 0.6754398941993713,
      "learning_rate": 9.514003294892917e-06,
      "loss": 0.1581,
      "step": 1350
    },
    {
      "epoch": 1.0862619808306708,
      "grad_norm": 0.5127113461494446,
      "learning_rate": 9.43163097199341e-06,
      "loss": 0.2073,
      "step": 1360
    },
    {
      "epoch": 1.0942492012779552,
      "grad_norm": 0.5530985593795776,
      "learning_rate": 9.349258649093904e-06,
      "loss": 0.1782,
      "step": 1370
    },
    {
      "epoch": 1.1022364217252396,
      "grad_norm": 0.5575737953186035,
      "learning_rate": 9.2668863261944e-06,
      "loss": 0.1724,
      "step": 1380
    },
    {
      "epoch": 1.110223642172524,
      "grad_norm": 0.5690838694572449,
      "learning_rate": 9.184514003294894e-06,
      "loss": 0.1782,
      "step": 1390
    },
    {
      "epoch": 1.1182108626198084,
      "grad_norm": 0.6683852076530457,
      "learning_rate": 9.102141680395387e-06,
      "loss": 0.1597,
      "step": 1400
    },
    {
      "epoch": 1.1182108626198084,
      "eval_loss": 0.2148953676223755,
      "eval_runtime": 313.0738,
      "eval_samples_per_second": 15.728,
      "eval_steps_per_second": 1.968,
      "step": 1400
    }
  ],
  "logging_steps": 10,
  "max_steps": 2504,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.2757763236993434e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
