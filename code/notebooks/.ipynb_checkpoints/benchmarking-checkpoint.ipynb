{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df049d0-8086-4b4b-9696-593de61c7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from statistics import mean\n",
    "from typing import Optional, Tuple, Dict, Any, List\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88fa315a-988d-410f-9009-8596a84fdc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_PATTERN = re.compile(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\")\n",
    "\n",
    "def parse_number(text: str) -> int | float | None:\n",
    "    match = NUMBER_PATTERN.findall(text.replace(\",\", \"\"))\n",
    "    if not match:\n",
    "        raise Exception(f\"No number found in text: {text}\")\n",
    "    val = match[-1]\n",
    "    if \"e\" in val.lower() or \".\" in val:\n",
    "        return float(val)\n",
    "    return int(val)\n",
    "\n",
    "\n",
    "def parse_gold_answer_number(answer: str) -> Optional[int | float]:\n",
    "    part = answer.split(\"####\")[-1].strip()\n",
    "    return parse_number(part)\n",
    "\n",
    "\n",
    "def parse_teacher_final_answer(answer: str) -> Optional[int | float]:\n",
    "    for line in answer.splitlines():\n",
    "        if line.lower().startswith(\"final answer:\"):\n",
    "            return parse_number(line.split(\":\", 1)[-1].strip())\n",
    "    raise Exception(f\"No 'Final Answer:' line found in teacher answer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a1dfd83-57e6-435c-add3-ed94e106f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one(question: str, max_new_tokens: int = 256, temperature: float = 0.0, top_p: float = 1.0, do_sample: bool = False, model) -> str:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prompt = build_prompt(question)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=do_sample,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "        text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "        return text[len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "031fa2bb-5876-4ed7-822e-5f313c20052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_split(dataset, greedy: bool = True, sc_k: int = 0, sc_temp: float = 0.7, sc_top_p: float = 0.95, max_new_tokens: int = 256, limit: Optional[int] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate on a HF dataset split with columns: 'question', 'answer'\n",
    "    (where 'answer' contains the gold GSM8K solution text that includes the final numeric answer).\n",
    "\n",
    "    - greedy=True: greedy decoding\n",
    "    - sc_k>0: self-consistency with k samples, majority vote on parsed numbers\n",
    "    \"\"\"\n",
    "    n = len(dataset) if limit is None else min(limit, len(dataset))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    missing = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        q = dataset[i][\"question\"]\n",
    "        gold_text = dataset[i][\"answer\"]\n",
    "        gold_num = parse_gold_answer_number(gold_text)\n",
    "\n",
    "        if sc_k and sc_k > 0:\n",
    "            preds = []\n",
    "            for _ in range(sc_k):\n",
    "                gen = generate_one(q, max_new_tokens=max_new_tokens, temperature=sc_temp, top_p=sc_top_p, do_sample=True)\n",
    "                num = parse_teacher_final_answer(gen)\n",
    "            if preds:\n",
    "                # majority vote\n",
    "                from collections import Counter\n",
    "                vote = Counter(preds).most_common(1)[0][0]\n",
    "                pred_num = vote\n",
    "            else:\n",
    "                pred_num = None\n",
    "        else:\n",
    "            gen = generate_one(q, max_new_tokens=max_new_tokens, temperature=0.0, top_p=1.0, do_sample=False)\n",
    "            pred_num = parse_teacher_final_answer(gen)\n",
    "\n",
    "        if gold_num is None or pred_num is None:\n",
    "            missing += 1\n",
    "        else:\n",
    "            correct += int(pred_num == gold_num)\n",
    "            total += 1\n",
    "\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Processed {i+1}/{n}: acc_so_far={(correct/max(1,total)):.4f}, missing={missing}\")\n",
    "\n",
    "    accuracy = correct / max(1, total)\n",
    "    coverage = (n - missing) / n\n",
    "    return {\"n\": n, \"correct\": correct, \"total\": total, \"accuracy\": accuracy, \"missing\": missing, \"coverage\": coverage}\n",
    "\n",
    "\n",
    "gsm8k_test = load_dataset(\"openai/gsm8k\", \"main\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "582c0efd-7dd6-4fdc-a20f-1facd1f30c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running greedy decoding on full test set…\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning greedy decoding on full test set…\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m res_greedy = \u001b[43mevaluate_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgsm8k_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreedy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msc_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGreedy:\u001b[39m\u001b[33m\"\u001b[39m, res_greedy)\n\u001b[32m      5\u001b[39m SC_K = \u001b[32m20\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mevaluate_split\u001b[39m\u001b[34m(dataset, greedy, sc_k, sc_temp, sc_top_p, max_new_tokens, limit)\u001b[39m\n\u001b[32m     30\u001b[39m         pred_num = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     gen = \u001b[43mgenerate_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     pred_num = parse_teacher_final_answer(gen)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gold_num \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m pred_num \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mgenerate_one\u001b[39m\u001b[34m(question, max_new_tokens, temperature, top_p, do_sample)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_one\u001b[39m(question: \u001b[38;5;28mstr\u001b[39m, max_new_tokens: \u001b[38;5;28mint\u001b[39m = \u001b[32m256\u001b[39m, temperature: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.0\u001b[39m, top_p: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m1.0\u001b[39m, do_sample: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmodel\u001b[49m.eval()\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m      4\u001b[39m         prompt = build_prompt(question)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Running greedy decoding on full test set…\")\n",
    "res_greedy = evaluate_split(gsm8k_test, greedy=True, sc_k=0, max_new_tokens=256, limit=None)\n",
    "print(\"Greedy:\", res_greedy)\n",
    "\n",
    "SC_K = 20\n",
    "print(f\"Running self-consistency with k={SC_K}…\")\n",
    "res_sc = evaluate_split(gsm8k_test, greedy=False, sc_k=SC_K, sc_temp=0.7, sc_top_p=0.95, max_new_tokens=256, limit=None)\n",
    "print(\"Self-Consistency:\", res_sc)\n",
    "\n",
    "# Compact summary\n",
    "def pct(x):\n",
    "    return f\"{100.0*x:.2f}%\"\n",
    "\n",
    "summary = {\n",
    "    \"greedy_accuracy\": pct(res_greedy[\"accuracy\"]),\n",
    "    \"greedy_coverage\": pct(res_greedy[\"coverage\"]),\n",
    "    \"sc_k\": SC_K,\n",
    "    \"sc_accuracy\": pct(res_sc[\"accuracy\"]),\n",
    "    \"sc_coverage\": pct(res_sc[\"coverage\"]),\n",
    "}\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b081d-6ac5-4ed8-9997-0529476e474b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv .venv)",
   "language": "python",
   "name": "engineering-thesis-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
